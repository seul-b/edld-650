---
title: "DARE-4"
author: "Seulbi Lee, Havi Khurana, Janette Avelar"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    highlight: tango
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      error = FALSE,
                      warning = FALSE)
```

```{r}
#Load package and read data
library(haven)
library(tidyverse)
library(kableExtra)
library(fixest)
library(MatchIt)
library(modelsummary)
library(here)

# read data
dat <- read_dta(here("DARE-4", "dumont_umansky_ECLSK.dta"))
```

#### A1.

The table shows counts and means of standardized teacher perceptions of student skills by English Learner (EL) program participation. For non-EL students, the average perceived skills in language are at 0.061 and in math at 0.073, indicating slightly above neutral or average perception. For EL students, the average perceived skills in language are at -0.392 and in math at -0.292, indicating a below-average perception. Figure 1 describes the distribution of standardized teacher perception scores for the two student groups, which are both left-skewed and have similar variance. It is evident that teachers perception scores are different for EL and non-EL students. The negative values for EL students suggest a perception of below-average abilities, while the positive values for non-EL students suggest a perception of above-average abilities.

However, this evidence should not be interpreted as a plausibly causal estimate of the effect of being classified as an EL student on teachers' perceptions because the data does not control for other variables that might influence teacher perceptions (such as student’s proficiency in the subject-matter).


```{r A1}
#summary(dat)

summary_table_a1 <- dat |> 
  group_by(elprgm) |> 
  summarise('N' = n(),
            'Language Skills'= round(mean(tlangk) , 3), 'Math Skills' = round(mean(tmathk) , 3)) |> 
    mutate(elprgm = if_else(elprgm == 1, "EL", "Non EL")) |> 
    rename('EL Status' = elprgm)

table_a1 <- kable(summary_table_a1, format = "html", caption = "Table 1. Summary of Teacher Perceptions of Student Skills by English Learner Program Participation", align = c('l', 'r', 'r', 'r')) |>
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, position = "center") |>
  column_spec(1, bold = T)

table_a1
```

```{r}
#Figure 1
dat %>%
  pivot_longer(cols = c(tlangk, tmathk),
               names_to = "skill",
               values_to = "score",
               names_prefix = "t") %>%
  mutate(skill = ifelse(skill == "langk", "Language skill", "Mathematics Skill")) %>%
  ggplot() +
  geom_boxplot(aes(x = factor(elprgm), y = score, fill = factor(elprgm)),
               show.legend = F) +
  scale_x_discrete(labels = c("No", "Yes")) +
  labs(x = "Attended EL program in Kindergarten",
       y = "Scaled Teacher Perception Score",
       fill = "",
       title = "Figure 1. Distribution of Teacher Perception Scores by Attendance in EL Program",
       caption = "Sample includes multilingual kindergarten students in the ECKLS dataset")+
  facet_wrap(~skill) +
  theme_minimal()+
  theme(panel.grid.major  = element_blank())
```

#### A2. 

Table 2 indicates there may be differences between EL and non-EL learners in their family SES status, demographic (Hispanic/Latinx), attendance rate, school location (rural), executive functions, academic performance, and their teachers’ teaching experience, as well as English language proficiency. This observed heterogeneity across groups underscores the need for a sophisticated matching algorithm in our analytical strategy for Section B. In Section B, we aim to create balanced groups of EL and Non-EL students across these covariates, reducing confounding and improving the robustness of our causal inferences regarding the impact of EL status on academic outcomes. By ensuring comparable groups, CEM allows us to attribute differences in outcomes more confidently to EL status rather than to underlying demographic or socioeconomic factors.

```{r A2}
full_sample_summary <- dat |>
  summarise(
    'Family SES (standardized)' = mean(ses, na.rm = TRUE),
    Female = mean(female, na.rm = TRUE) * 100, 
    'Hispanic/Latinx' =  mean(hisp, na.rm = TRUE) * 100, 
    'Chronically absent in kindergarten' = mean(chrabsk, na.rm = TRUE) * 100,  
    'Rural location' = mean(rural, na.rm = TRUE) * 100, 
    'Executive function' = mean(kexecfunc1, na.rm = TRUE),
    'Preschool Language Assessment Scale' = mean(prelas, na.rm = TRUE),
    'English Basic Reading Skill' = mean(ebrs, na.rm = TRUE),
    'Reading assessment' = mean(kread, na.rm = TRUE),
    'Math assessment' = mean(kmath, na.rm = TRUE),
    'Teacher Experience' = mean(tchrexp, na.rm = TRUE)
  ) |>
  mutate(Group = "Full Sample") 

el_summary <- dat |>
  group_by(elprgm) |>
  summarise(
    'Family SES (standardized)' = mean(ses, na.rm = TRUE),
    Female = mean(female, na.rm = TRUE) * 100, 
    'Hispanic/Latinx' =  mean(hisp, na.rm = TRUE) * 100, 
    'Chronically absent in kindergarten' = mean(chrabsk, na.rm = TRUE) * 100,  
    'Rural location' = mean(rural, na.rm = TRUE) * 100,  
    'Executive function' = mean(kexecfunc1, na.rm = TRUE),
    'Preschool Language Assessment Scale' = mean(prelas, na.rm = TRUE),
    'English Basic Reading Skill' = mean(ebrs, na.rm = TRUE),
    'Reading assessment' = mean(kread, na.rm = TRUE),
    'Math assessment' = mean(kmath, na.rm = TRUE),
    'Teacher Experience' = mean(tchrexp, na.rm = TRUE)
  ) |>
  mutate(Group = if_else(elprgm == 1, "EL", "Non-EL")) |> 
  ungroup() |>
    select(-elprgm)

combined_summary <- full_sample_summary |>
  bind_rows(el_summary) |>
  pivot_longer(cols = -Group, names_to = "Measure", values_to = "Value")

combined_summary_wide <- combined_summary |>
  pivot_wider(names_from = Group, values_from = Value)

combined_summary_wide <- combined_summary_wide |>
  slice(-10) |> 
  mutate(across(c(`Full Sample`, `Non-EL`, `EL`), ~ case_when(
    Measure %in% c("Female", "Chronically absent in kindergarten", "Rural location", "Hispanic/Latinx") ~ paste0(sprintf("%.2f", round(., 2)), "%"),
    TRUE ~ sprintf("%.2f", round(., 2))
  )))

table_a2 <- kable(combined_summary_wide, format = "html",
                  caption = "Table 2. Comparisons of Student and School Characteristics and Test Scores Between Full Sample, EL, and Non-EL Students") |>
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = F,
    position = "center"
  ) 

table_a2
```

#### B1.

To estimate the probability that a student who lives in a home where a language other than English is spoken will be identified as an English learner, we used the following model:

$$P(EL_i) = \beta_0 + \beta_1PreLAS_i + \beta_2 EBRS_i + \beta_3SES_i + \beta_4RURAL_i + \beta_5Female_i + \beta_6HISP_i + \epsilon_i$$

Figure 2 shows our region of common support prior to matching. The amount of overlap we see in the histograms indicates that our EL and non-EL groups in the full sample have comparable distributions of the probability scores derived from the key matching variables. Thus, we would be successful in matching across variables without losing much sample size, and feel that our comparison across these groups will result in a reliable estimate.



```{r}
dat <- dat |>
  mutate(
    race = as.factor(race),
#   elprgm = as.factor(elprgm),
    female = as.factor(female),
    rural = as.factor(rural),
    hisp = as.factor(hisp)
  )
```

```{r B1}
# 1. Fit logistic selection model estimating probability of home language, given covariates
pscores <- feglm(elprgm ~ prelas + ebrs + ses + rural + female + hisp, family=c("logit"), data=dat)

#summary(pscores)

# 2. Estimate fitted probability of selection into treatment for each individual
dat$p_score <- predict(pscores, type = "response") 

#head(pscore_df)

# 3. Examine common support
ggplot(dat, aes(p_score, fill = as.factor(elprgm))) + 
  geom_density(alpha=0.4) + 
  theme_minimal(base_size = 12) + 
  labs(x = "Probability of EL Identification",
       fill = "Identified as an EL",
       title = "Figure 2. Region of Common Support on Unmatched Sample",
       y = "Density") +
  scale_fill_discrete(labels = c("No", "Yes"))+
  scale_x_continuous(limits = c(0,1))
```

#### B2. 

Multilingual students, at their first entry to school, are screened for EL classification based on their English proficiency scores. The identification strategy leverages natural variations in EL classification criteria across locales, creating a quasi-experimental design to assess how EL status influences teacher perceptions. The strategy assumes that these variations effectively randomize EL classification among students with similar English proficiency, allowing for a comparison that isolates the effect of EL status. In other words, our critical assumption is ‘selection on observables’, i.e., after we adjust a student's latent English proficiency, assignment to EL status is as good as random.

The matching procedure used, coarsened exact matching, adjusts for English proficiency using two measures (PreLAS and EBRS), and other student-level covariates, including socio-economic status, gender, whether location of school is rural and whether student is Hispanic/Latinx. We matched exactly on the three dichotomous variables - Female, Hispanic/Latinx, and Rural, and used quintiles as cut-points for the remaining three continuous variables, similar to the approach adopted by Umansky and Dumont (2021), since such quintiles can reduce more than 90% of the bias. In the resulting sample, where the only random difference between groups is EL status, we excluded 223 non-EL and 321 EL students from the original sample, indicating that the matched sample more accurately represents comparable students across EL classifications.


```{r B2}
#### Step 1. Define coarsened bins of covariates within which to match

# Quintiles for prelas
#summary(dat$prelas)
prelascuts <-  quantile(dat$prelas, probs = c(0.2, 0.34, 0.6, 0.8, 1))

# Quintiles for ebrs
#summary(dat$ebrs)
ebrscuts <- quantile(dat$ebrs, probs = c(0.2, 0.34, 0.6, 0.8, 1))

# Quintiles for ses
#summary(dat$ses)
sescuts <- quantile(dat$ses, probs = c(0.2, 0.34, 0.6, 0.8, 1))

# dat$prelas_coarsened <- cut(dat$prelas, breaks = c(-Inf, prelascuts, Inf), include.lowest = TRUE)
# dat$ebrs_coarsened <- cut(dat$ebrs, breaks = c(-Inf, ebrscuts, Inf), include.lowest = TRUE)
# dat$ses_coarsened <- cut(dat$ses, breaks = c(-Inf, sescuts, Inf), include.lowest = TRUE)

#### Step 2. Define matching bins 
cem <- matchit(elprgm ~  prelas + ebrs + ses + rural + female + hisp, 
      cutpoints=list(prelas = prelascuts,
                     ebrs = ebrscuts,
                     ses = sescuts),
               method = "cem", 
               data = dat)
```


```{r B2-Assess}
df_cem <- match.data(cem)

# Have we dropped any? Yes
All <- table(dat$elprgm)
Matched <- table(df_cem$elprgm)
Unmatched <- All - Matched

All_df <- as.data.frame(All)
Matched_df <- as.data.frame(Matched)
Unmatched_df <- as.data.frame(Unmatched)

names(All_df)[2] <- "Original"
names(Matched_df)[2] <- "Matched"
names(Unmatched_df)[2] <- "Unmatched"

Table <- merge(All_df, Matched_df, by = "Var1")
Table <- merge(Table, Unmatched_df, by = "Var1")
names(Table)[1] <- "EL Status"
Table$`EL Status` <- factor(Table$`EL Status`, labels = c("No", "Yes"))

kable(Table, format = "html",
                  caption = "Table 3. Sample Size after CEM Matching") |>
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = F,
    position = "center"
  ) 
```


```{r B3}
# Table for matched and unmatched characteristics
a <- summary(cem)
#View(a)

table_names <- c("Pre-LAS Score", "EBRS Score", "SES Index",
                 "Rural", "Female", "Hispanic")

chr_unmatched <- a$sum.all[c(1:3,5,7,9), 1:3] %>%
    as.data.frame() %>%
    mutate(Measure = table_names,
           across(-Measure, ~round(.x,2))) %>%
    select(Measure, everything())

chr_matched <- a$sum.matched[c(1:3,5,7,9), 1:3] %>%
    as.data.frame() %>%
    mutate(Measure = table_names,
           across(-Measure, ~round(.x,2))) %>%
    select(Measure, everything())

chr_all <- rbind(chr_unmatched, chr_matched)

kable(chr_all,format = "html",
                  caption = "Table 4. Comparing Matching Variables in the Unmatched and Matched CEM Samples", row.names = FALSE) |>
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = F,
    position = "center"
  ) |>
  pack_rows("Unmatched Sample", 1, 6) %>%
  pack_rows("Matched Sample", 7, 12)
```

#### B3.

Figure 3 illustrates the region of common support in our matched sample. The overlapping area has increased considerably in comparison to Figure 2, indicating that our groups are more balanced. Ideally, post-matching, the mean differences for each variable between the EL and non-EL groups should be statistically insignificant, and we do indeed see that the mean differences go down after matching (see Table 4). We could choose to undergo further re-matching procedures to reduce group differences further, however, this may be unnecessary as both visual inspection and a comparison of mean differences indicate our groups are well-balanced.

```{r B3 figure}
# #regenerate pscores
# pscores <- feglm(elprgm ~ prelas + ebrs + ses + rural + female + hisp, family=c("logit"), weights = df_cem$weights, data = df_cem)
# df_cem$p_score <- predict(pscores, type = "response") 
# #figure
# df_cem %>%
#   mutate(elprgm = ifelse(elprgm == 0, "No", "Yes")) %>%
#   ggplot(., aes(p_score, fill = as.factor(elprgm))) +
#   geom_density(alpha=0.4) +
#   theme_minimal(base_size = 12) +
#   xlab("Probability of EL Identification") +
#   labs(title = "Figure 3. Region of Common Support on Matched Sample",
#        fill = "Identified as an EL")

df_cem %>% group_by(elprgm, subclass) %>% 
            summarise(count= n()) %>% 
  mutate(identification = count/sum(count)) %>% 
  ggplot(., aes(subclass, identification, fill = as.factor(elprgm))) + 
  geom_col(alpha=0.6, position = position_dodge()) + 
  theme_minimal() + 
  labs(title = "Figure 3. Region of Common Support on Matched Sample (CEM)",
       fill = "Identified as an EL",
       x = "Subclassification by English Proficiency, Localities, Sex, and Racial Background") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  scale_fill_discrete(labels = c("No", "Yes"))
```

```{r B3 table, include = FALSE, eval = FALSE}
#specify vars of interest for subsetting
vars <- c("prelas", "ebrs", "kmath", "kread", "kexecfunc1", "kexecfunc2", "female", "hisp", "rural", "ses")
#specify labs for rename
labs <- c("PreLas (0-20)", "EBRS (0-20)", "Math assessment", "Reading assessment", "Executive function 1 (0-18)", "Executive function 2 (393-603)", "Female", "Latinx", "Rural", "Socioeconomic status")
#group sums
n <- data.frame(Variable = "N", m_0_post = 722, m_0_pre = 945, m_1_post = 900, m_1_pre = 1221)
#join
dat_join <- dat %>% 
  select(elprgm, all_of(vars)) %>% 
  mutate(time = "pre")
match_join <- df_cem %>% 
  select(elprgm, all_of(vars)) %>% 
  mutate(time = "post")
combined <- dat_join %>%
  full_join(match_join, by = c("elprgm", vars, "time"))
#table data
combined_table <- combined %>% 
  mutate(female = as.numeric(female),
         hisp = as.numeric(hisp),
         rural = as.numeric(rural)) %>% 
  group_by(elprgm, time) %>% 
  dplyr::summarize(across(c(vars),
           list(n = ~n(), m = ~round(mean(., na.rm = TRUE), 2)),
           .names = "{.col}.{.fn}")) %>% 
  pivot_longer(cols = -c(elprgm, time),
               names_to = c("Variable",".value"),
               names_pattern = "([^.]+)\\.(n|m)") %>% 
  pivot_wider(names_from = c(elprgm, time),
              values_from = c(n, m),
              names_sep = "_") %>% 
  select(-starts_with("n")) %>% 
  bind_rows(n)

## Add t and p values
t_tests <- lapply(vars, function(var_name) {
  t.test(reformulate("elprgm", response = var_name), data = combined_table)
})
stats <- data.frame(
  Variable = vars,
  p = sapply(t_tests, function(x) x$p.value))

combined_table <- left_join(combined_table, stats, by = "Variable") %>% 
  mutate(Variable = case_when(
    Variable == "prelas" ~ "PreLas (0-20)",
    Variable == "ebrs" ~ "EBRS (0-20)",
    Variable == "kmath" ~ "Math assessment",
    Variable == "kread" ~ "Reading assessment",
    Variable == "kexecfunc1" ~ "Executive function 1 (0-18)",
    Variable == "kexecfunc2" ~ "Executive function 2 (393-603)",
    Variable == "female" ~ "Female",
    Variable == "hisp" ~ "Latinx",
    Variable == "ses" ~ "Socioeconomic status",
    Variable == "rural" ~ "Rural",
    Variable == "N" ~ "N"
  ),
  p_pre = case_when(
    p < .001 ~ "***",
    p > .05 ~ "ns",
    is.na(p) ~ ""
  ),
  p_post = case_when(
    p < .001 ~ "***",
    p > .05 ~ "ns",
    is.na(p) ~ ""
  )) %>% 
  select(Variable, m_0_pre, m_1_pre, p_pre, m_0_post, m_1_post, p_post)
#table function
nice_table <- function(data, separate.header = TRUE, title) {
  blank_names <- rep("", ncol(data))
  if(separate.header) {
    kable(data, "html", caption = title, col.names = blank_names) %>% 
      kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
      add_header_above(c(" " = 1, "Non-EL" = 1, "EL" = 1, "t-test" = 1, "Non-EL" = 1, "EL" = 1, "t-test" = 1)) %>% 
      add_header_above(c(" " = 1, "Prematched Sample" = 3, "Postmatched Sample" = 3))
  } else {
    kable(data, "html") %>% 
      kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
  }
}
#table
nice_table(combined_table, 
          separate.header = TRUE, 
          title = "Table 3. Comparison of Characteristics Before and After Matching")
#clean up
rm(dat_join, match_join, n, combined, stats, t_tests, labs, vars, nice_table)
>>>>>>> Stashed changes
```



```{r B4 CEM Model}
# CEM Models
lang_cem <- feols(tlangk ~ factor(elprgm) + prelas + ebrs + ses + rural + female + hisp +
                kread + kmath + chrabsk + kexecfunc1 + kexecfunc2 + tchrexp,
              weights = df_cem$weights, data = df_cem) 

math_cem <- feols(tmathk ~ factor(elprgm) + prelas + ebrs + ses + rural + female + hisp +
                kread + kmath + chrabsk + kexecfunc1 + kexecfunc2 + tchrexp,
             weights = df_cem$weights, data = df_cem) 
```

#### B4 and B5

```{r B5 Models}
# OLS
lang_sc1 <- feols(tlangk ~ factor(elprgm) + prelas + ebrs + ses + rural + female + hisp +
                kread + kmath + chrabsk + kexecfunc1 + kexecfunc2 + tchrexp, data = dat) 

# PSM
matched_psm <- matchit(factor(elprgm)~ prelas + ebrs + ses + rural + female + hisp , method="nearest", 
                   replace=T, discard="both", data=dat)
df_psm <- match.data(matched_psm)
#summary(matched_psm)
# For quality of matches, a table here on balanced data
# And a plot of overlapping propensity scores

lang_sc2 <- feols(tlangk ~ factor(elprgm) + prelas + ebrs + ses + rural + female + hisp +
                kread + kmath + chrabsk + kexecfunc1 + kexecfunc2 + tchrexp, data = df_psm) 
#summary(lang_sc2)

math_sc1 <- feols(tmathk ~ factor(elprgm) + prelas + ebrs + ses + rural + female + hisp +
                kread + kmath + chrabsk + kexecfunc1 + kexecfunc2 + tchrexp, data = dat) 

# PSM
#matched_psm <- matchit(factor(elprgm)~ prelas + ebrs + ses + rural + female + hisp , method="nearest", 
#                   replace=T, discard="both", data=dat)
#df_psm <- match.data(matched_psm)
#summary(matched_psm)

math_sc2 <- feols(tmathk ~ factor(elprgm) + prelas + ebrs + ses + rural + female + hisp +
                kread + kmath + chrabsk + kexecfunc1 + kexecfunc2 + tchrexp, data = df_psm) 
```

```{r Quality of PSM Matches}
# Table for matched and unmatched characteristics
psm_matches <- summary(matched_psm)
#View(a)

table_names <- c("Pre-LAS Score", "EBRS Score", "SES Index",
                 "Rural", "Female", "Hispanic")

chr_unmatched <- psm_matches$sum.all[c(1:3,5,7,9), 1:3] %>%
    as.data.frame() %>%
    mutate(Measure = table_names,
           across(-Measure, ~round(.x,2))) %>%
    select(Measure, everything())

chr_matched <- psm_matches$sum.matched[c(1:3,5,7,9), 1:3] %>%
    as.data.frame() %>%
    mutate(Measure = table_names,
           across(-Measure, ~round(.x,2))) %>%
    select(Measure, everything())

chr_all <- rbind(chr_unmatched, chr_matched)

kable(chr_all,format = "html",
                  caption = "Table 5. Comparing Matching Variables in the Unmatched and Matched PSM Samples", row.names = FALSE) |>
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = F,
    position = "center"
  ) |>
  pack_rows("Unmatched Sample", 1, 6) %>%
  pack_rows("Matched Sample", 7, 12)
#Figure
ggplot(df_psm, aes(p_score, fill = as.factor(elprgm))) + 
  geom_density(alpha=0.4) + 
  theme_minimal(base_size = 12) + 
  labs(x = "Probability of EL Identification",
       fill = "Identified as an EL",
       title = "Figure 4. Region of Common Support on Matched Sample (PSM)",
       y = "Density") +
  scale_fill_discrete(labels = c("No", "Yes")) +
  scale_x_continuous(limits = c(0,1))
```

```{r Table}
modelsummary(models = list("CEM" = lang_cem,
                      "SA1: Naive OLS" = lang_sc1,
                      "SA2: PSM" = lang_sc2,
                      "CEM" = math_cem,
                      "SA1: Naive OLS" = math_sc1,
                      "SA2: PSM" = math_sc2),
             vcov = "robust",
             stars = TRUE,
             coef_map = c("factor(elprgm)1" = "EL Identification"),
              gof_omit= "Adj|Pseudo|Log|Within|AIC|BIC|Std|F|RMSE",
             title = "Table 6. Effect of EL Identification on Teacher Perception on Skills in Kindergarten",
             notes = "We used the following variables for matching: Female, Hispanic/Latinx, School in rural area, SES, PreLAS and EBRS scores. We included all the matching variables as covariated in the models. Additional covariates were chronic absentiism, math, reading, and executive functioning scores in Kindergarten, and teacher's years of experience. Robust standard errors are reported.")  |>
     add_header_above(c(" " = 1, "Language Skills" = 3, "Math Skills" = 3))
   
```


To find the impact of EL Status on teacher perception, we estimated the following model using our matched sample,

$$Perception_i = \gamma_0 + \gamma_1*EL_i + \gamma_2*X + \delta_i$$

Here, the outcome is the standardized score on language and math skills for ith student in Kindergarten. EL is an indicator variable for whether a student attended EL program in the spring term of Kindergarten. X represents a vector of student-level covariates, including, PreLAS and EBRS scores, SES index, whether school was located in rural area, whether student was female or Hispanic/Latinx, student’s reading, math, and executive functioning scores in Kindergarten, a binary indicator of whether a student was chronically absent, and student’s teacher’s years of experience. $\delta$ is the student-level error. Since we adjusted for variables we matched on, our estimates are ‘doubly robust’. Note that, in the paper, error is clustered at the school level. In this analysis, we use robust standard errors. Our results are presented in Table 6 (columns 1 and 4). We found that an EL identification doesn’t significantly affect a teacher's perception of student’s language or math skills in Kindergarten (p > 0.05). Our estimates are fairly small (0.03 SD) and of inconsistent direction (negative for English skills and positive for Math skills). This is different from the paper, where the authors found a non-significant effect yet slightly bigger effects, -0.11 SD for language skills and -0.88 SD for math skills. One possible reason is that more school-level covariates were used in the original analysis. 

We also present sensitivity analysis estimates from Naive OLS strategy and Propensity Score Matching methods in the Table. We use the same covariates across all models. For Propensity Score Matching (PSM), we used the same matching variables as in CEM, and used the nearest neighbor matching algorithm. Table 5 and Figure Y show the comparison of unmatched and matched samples on key variables, and the region of common support. We see that any observable differences became non-existent in the matched sample.  However, one con of using the PSM technique is that the estimates are model-dependent and we lose transparency is the underlying matching process. Our PSM matched sample is smaller than the one reported in the paper, since the paper used more variables to match on, whereas we used the same matching variables as in CEM. 

As expected, the Naive OLS estimates over-state the negative impact of EL identification on teacher perception, between 0.1-0.14 SD decrease on average, and is significant. In the estimates calculated using the PSM sample, we find a statistically significant (p < 0.05) though somewhat smaller effect compared to the OLS. For language skills, we estimate that EL identification decreases teacher perception scores by 0.09 SD, and for math skills, there is an estimated decrease of 0.1 SD. This is also in line with the original analysis, where the authors found significant estimates in the Naive OLS and PSM matched techniques. 

#### B6.
Our replication of Umansky and Dumont’s (2021) study generated similar results. We found that EL identification has no impact on teacher perception of language skills in kindergarten. We found less consistent evidence for math skills, with a slightly positive nonsignificant effect when using coarsened-exact matching and a statistically significant negative effect when using propensity score matching. The differences across math and language skills may indicate differences in the magnitude of negative perception dependent upon academic domain. However, these differences in effect size and statistical significance also suggest our results are sensitive to the matching technique used, urging cautious interpretation and further research. An additional limitation of this study lies in our selection of observable variables. Although we match students on key observable characteristics, there may be further unobserved factors influencing both the likelihood of EL classification and teacher perception. If these unobserved factors systematically differ between our matched EL and non-EL groups, they may result in biased causal estimates. We acknowledge this limitation and recommend further research exploring additional factors that may impact identification and teacher perception.